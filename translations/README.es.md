<div align="center">

<img src="/docs/logo.png" alt="VideoLingo Logo" height="140">

# Conectando el Mundo, Cuadro por Cuadro

<a href="https://trendshift.io/repositories/12200" target="_blank"><img src="https://trendshift.io/api/badge/repositories/12200" alt="Huanshere%2FVideoLingo | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"/></a>

[**English**](/README.md)ï½œ[**ç®€ä½“ä¸­æ–‡**](/translations/README.zh.md)ï½œ[**ç¹é«”ä¸­æ–‡**](/translations/README.zh-TW.md)ï½œ[**æ—¥æœ¬èª**](/translations/README.ja.md)ï½œ[**EspaÃ±ol**](/translations/README.es.md)ï½œ[**Ğ ÑƒÑÑĞºĞ¸Ğ¹**](/translations/README.ru.md)ï½œ[**FranÃ§ais**](/translations/README.fr.md)

</div>

## ğŸŒŸ DescripciÃ³n General ([Â¡Prueba VL Gratis!](https://videolingo.io))

VideoLingo es una herramienta todo en uno para traducciÃ³n, localizaciÃ³n y doblaje de videos, diseÃ±ada para generar subtÃ­tulos de calidad Netflix. Elimina las traducciones mecÃ¡nicas y los subtÃ­tulos de mÃºltiples lÃ­neas mientras agrega doblaje de alta calidad, permitiendo compartir conocimiento globalmente a travÃ©s de las barreras del idioma.

CaracterÃ­sticas principales:
- ğŸ¥ Descarga de videos de YouTube mediante yt-dlp

- **ğŸ™ï¸ Reconocimiento de subtÃ­tulos a nivel de palabra y baja ilusiÃ³n con WhisperX**

- **ğŸ“ SegmentaciÃ³n de subtÃ­tulos impulsada por NLP e IA**

- **ğŸ“š TerminologÃ­a personalizada + generada por IA para una traducciÃ³n coherente**

- **ğŸ”„ Proceso de 3 pasos TraducciÃ³n-ReflexiÃ³n-AdaptaciÃ³n para calidad cinematogrÃ¡fica**

- **âœ… Solo subtÃ­tulos de una lÃ­nea, estÃ¡ndar Netflix**

- **ğŸ—£ï¸ Doblaje con GPT-SoVITS, Azure, OpenAI y mÃ¡s**

- ğŸš€ Inicio y procesamiento con un clic en Streamlit

- ğŸŒ Soporte multilingÃ¼e en la interfaz de Streamlit

- ğŸ“ Registro detallado con reanudaciÃ³n de progreso

Diferencia con proyectos similares: **Solo subtÃ­tulos de una lÃ­nea, calidad superior de traducciÃ³n, experiencia de doblaje perfecta**

## ğŸ¥ Demo

<table>
<tr>
<td width="33%">

### SubtÃ­tulos Duales
---
https://github.com/user-attachments/assets/a5c3d8d1-2b29-4ba9-b0d0-25896829d951

</td>
<td width="33%">

### ClonaciÃ³n de Voz Cosy2
---
https://github.com/user-attachments/assets/e065fe4c-3694-477f-b4d6-316917df7c0a

</td>
<td width="33%">

### GPT-SoVITS con mi voz
---
https://github.com/user-attachments/assets/47d965b2-b4ab-4a0b-9d08-b49a7bf3508c

</td>
</tr>
</table>

### Soporte de Idiomas

**Soporte de idiomas de entrada (mÃ¡s por venir):**

ğŸ‡ºğŸ‡¸ InglÃ©s ğŸ¤© | ğŸ‡·ğŸ‡º Ruso ğŸ˜Š | ğŸ‡«ğŸ‡· FrancÃ©s ğŸ¤© | ğŸ‡©ğŸ‡ª AlemÃ¡n ğŸ¤© | ğŸ‡®ğŸ‡¹ Italiano ğŸ¤© | ğŸ‡ªğŸ‡¸ EspaÃ±ol ğŸ¤© | ğŸ‡¯ğŸ‡µ JaponÃ©s ğŸ˜ | ğŸ‡¨ğŸ‡³ Chino* ğŸ˜Š

> *El chino utiliza un modelo whisper mejorado con puntuaciÃ³n por ahora...

**La traducciÃ³n admite todos los idiomas, mientras que el idioma del doblaje depende del mÃ©todo TTS elegido.**

## InstalaciÃ³n

Â¿Tienes algÃºn problema? Chatea con nuestro agente de IA en lÃ­nea gratuito [**aquÃ­**](https://share.fastgpt.in/chat/share?shareId=066w11n3r9aq6879r4z0v9rh) para ayudarte.

> **Nota:** Para usuarios de Windows con GPU NVIDIA, sigue estos pasos antes de la instalaciÃ³n:
> 1. Instala [CUDA Toolkit 12.6](https://developer.download.nvidia.com/compute/cuda/12.6.0/local_installers/cuda_12.6.0_560.76_windows.exe)
> 2. Instala [CUDNN 9.3.0](https://developer.download.nvidia.com/compute/cudnn/9.3.0/local_installers/cudnn_9.3.0_windows.exe)
> 3. Agrega `C:\Program Files\NVIDIA\CUDNN\v9.3\bin\12.6` a tu PATH del sistema
> 4. Reinicia tu computadora

> **Nota:** Se requiere FFmpeg. Por favor, instÃ¡lalo a travÃ©s de gestores de paquetes:
> - Windows: ```choco install ffmpeg``` (vÃ­a [Chocolatey](https://chocolatey.org/))
> - macOS: ```brew install ffmpeg``` (vÃ­a [Homebrew](https://brew.sh/))
> - Linux: ```sudo apt install ffmpeg``` (Debian/Ubuntu)

1. Clona el repositorio

```bash
git clone https://github.com/Huanshere/VideoLingo.git
cd VideoLingo
```

2. Instala las dependencias (requiere `python=3.10`)

```bash
conda create -n videolingo python=3.10.0 -y
conda activate videolingo
python install.py
```

3. Inicia la aplicaciÃ³n

```bash
streamlit run st.py
```

### Docker
Alternativamente, puedes usar Docker (requiere CUDA 12.4 y versiÃ³n del controlador NVIDIA >550), consulta la [documentaciÃ³n de Docker](/docs/pages/docs/docker.en-US.md):

```bash
docker build -t videolingo .
docker run -d -p 8501:8501 --gpus all videolingo
```

## APIs
VideoLingo admite formato de API similar a OpenAI y varias interfaces TTS:
- LLM: `claude-3-5-sonnet`, `gpt-4.1`, `deepseek-v3`, `gemini-2.0-flash`, ... (ordenados por rendimiento, ten cuidado con gemini-2.5-flash...)
- WhisperX: Ejecuta whisperX localmente o usa la API de 302.ai
- TTS: `azure-tts`, `openai-tts`, `siliconflow-fishtts`, **`fish-tts`**, `GPT-SoVITS`, `edge-tts`, `*custom-tts`(Â¡Puedes modificar tu propio TTS en custom_tts.py!)

> **Nota:** VideoLingo funciona con **[302.ai](https://gpt302.saaslink.net/C2oHR9)** - una clave API para todos los servicios (LLM, WhisperX, TTS). Â¡O ejecÃºtalo localmente con Ollama y Edge-TTS gratis, sin necesidad de API!

Para instrucciones detalladas de instalaciÃ³n, configuraciÃ³n de API y modo por lotes, consulta la documentaciÃ³n: [English](/docs/pages/docs/start.en-US.md) | [ä¸­æ–‡](/docs/pages/docs/start.zh-CN.md)

## Limitaciones Actuales

1. El rendimiento de transcripciÃ³n de WhisperX puede verse afectado por el ruido de fondo del video, ya que utiliza el modelo wav2vac para la alineaciÃ³n. Para videos con mÃºsica de fondo fuerte, activa la Mejora de SeparaciÃ³n de Voz. AdemÃ¡s, los subtÃ­tulos que terminan con nÃºmeros o caracteres especiales pueden truncarse temprano debido a la incapacidad de wav2vac para mapear caracteres numÃ©ricos (por ejemplo, "1") a su forma hablada ("uno").

2. El uso de modelos mÃ¡s dÃ©biles puede provocar errores durante los procesos intermedios debido a los estrictos requisitos de formato JSON para las respuestas. Si ocurre este error, elimina la carpeta `output` y vuelve a intentarlo con un LLM diferente, de lo contrario, la ejecuciÃ³n repetida leerÃ¡ la respuesta errÃ³nea anterior causando el mismo error.

3. La funciÃ³n de doblaje puede no ser 100% perfecta debido a las diferencias en las velocidades de habla y entonaciÃ³n entre idiomas, asÃ­ como al impacto del paso de traducciÃ³n. Sin embargo, este proyecto ha implementado un extenso procesamiento de ingenierÃ­a para las velocidades de habla para garantizar los mejores resultados posibles de doblaje.

4. **El reconocimiento de transcripciÃ³n de video multilingÃ¼e solo mantendrÃ¡ el idioma principal**. Esto se debe a que whisperX utiliza un modelo especializado para un solo idioma al alinear forzosamente los subtÃ­tulos a nivel de palabra, y eliminarÃ¡ los idiomas no reconocidos.

5. **No se pueden doblar mÃºltiples personajes por separado**, ya que la capacidad de distinciÃ³n de hablantes de whisperX no es suficientemente confiable.

## ğŸ“„ Licencia

Este proyecto estÃ¡ licenciado bajo la Licencia Apache 2.0. Un agradecimiento especial a los siguientes proyectos de cÃ³digo abierto por sus contribuciones:

[whisperX](https://github.com/m-bain/whisperX), [yt-dlp](https://github.com/yt-dlp/yt-dlp), [json_repair](https://github.com/mangiucugna/json_repair), [BELLE](https://github.com/LianjiaTech/BELLE)

## ğŸ“¬ ContÃ¡ctame

- EnvÃ­a [Issues](https://github.com/Huanshere/VideoLingo/issues) o [Pull Requests](https://github.com/Huanshere/VideoLingo/pulls) en GitHub
- EnvÃ­ame un DM en Twitter: [@Huanshere](https://twitter.com/Huanshere)
- EnvÃ­ame un correo a: team@videolingo.io

## â­ Historial de Estrellas

[![Star History Chart](https://api.star-history.com/svg?repos=Huanshere/VideoLingo&type=Timeline)](https://star-history.com/#Huanshere/VideoLingo&Timeline)

---

<p align="center">Si encuentras Ãºtil VideoLingo, Â¡por favor dame una â­ï¸!</p> 