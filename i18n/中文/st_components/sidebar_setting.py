import os, sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from st_components.imports_and_utils import ask_gpt
import streamlit as st
from core.config_utils import update_key, load_key

def config_input(label, key, help=None):
    """Generic config input handler"""
    val = st.text_input(
        label, 
        value=load_key(key), 
        help=help,
        key=f"config_input_{key}"
    )
    if val != load_key(key):
        update_key(key, val)
    return val

def page_setting():
    # LLMé…ç½®éƒ¨åˆ†
    st.subheader("LLMé…ç½®")
    
    # æ¨¡å‹é…ç½®ç®¡ç†
    st.subheader("æ¨¡å‹é…ç½®")
    
    # è·å–ç°æœ‰æ¨¡å‹åˆ—è¡¨
    models = load_key("llm_models")
    
    # æ·»åŠ æ–°æ¨¡å‹æŒ‰é’®
    if st.button("â• æ·»åŠ æ–°æ¨¡å‹"):
        new_model_name = f"model_{len(models)}"
        update_key(f"llm_models.{new_model_name}", {
            "key": "",
            "base_url": "",
            "model": ""
        })
        st.rerun()

    # æ˜¾ç¤ºç°æœ‰æ¨¡å‹é…ç½®
    for model_name in models:
        st.markdown(f"### ğŸ“‘ {model_name}")
        # æ¨¡å‹åç§°ç¼–è¾‘ï¼ˆå¯é€‰ï¼‰
        new_name = st.text_input("æ¨¡å‹åç§°", value=model_name, key=f"name_{model_name}")
        
        # åŸºç¡€é…ç½®
        config_input(f"APIå¯†é’¥", f"llm_models.{model_name}.key")
        config_input(f"åŸºç¡€URL", f"llm_models.{model_name}.base_url")
        config_input(f"æ¨¡å‹", f"llm_models.{model_name}.model")
        
        # æµ‹è¯•å’Œåˆ é™¤æŒ‰é’®
        c1, c2, c3 = st.columns([3, 1, 1])
        with c2:
            if st.button("ğŸ” æµ‹è¯•", key=f"test_{model_name}"):
                api_set = load_key(f"llm_models.{model_name}")
                st.toast(
                    "APIå¯†é’¥æœ‰æ•ˆ" if check_api(api_set) else "APIå¯†é’¥æ— æ•ˆ",
                    icon="âœ…" if check_api(api_set) else "âŒ"
                )
        with c3:
            if len(models) > 1 and st.button("ğŸ—‘ï¸ åˆ é™¤", key=f"delete_{model_name}"):
                models_dict = load_key("llm_models")
                del models_dict[model_name]
                update_key("llm_models", models_dict)
                st.rerun()
        st.divider()

    # é˜¶æ®µé…ç½®
    st.subheader("é˜¶æ®µé…ç½®")
    stages = {
        "all": "æ‰€æœ‰é˜¶æ®µ",
        "align": "å­—å¹•å¯¹é½",
        "split": "å­—å¹•åˆ†å‰²",
        "summarize": "æ€»ç»“",
        "translate_faithfulness": "ç¿»è¯‘ï¼ˆç²¾ç¡®ï¼‰",
        "translate_expressiveness": "ç¿»è¯‘ï¼ˆä¼˜é›…ï¼‰",
        "reduce": "å­—å¹•ç¼©å‡"
    }
    
    for stage_key, stage_name in stages.items():
        col1, col2 = st.columns([3, 2])
        with col1:
            st.write(stage_name)
        with col2:
            current_model = load_key(f"llm_stages.{stage_key}")
            selected_model = st.selectbox(
                "æ¨¡å‹",
                options=list(models.keys()),
                index=list(models.keys()).index(current_model),
                key=f"stage_{stage_key}",
                label_visibility="collapsed"
            )
            if selected_model != current_model:
                update_key(f"llm_stages.{stage_key}", selected_model)

    with st.expander("è½¬å†™å’Œå­—å¹•è®¾ç½®", expanded=True):
        c1, c2 = st.columns(2)
        with c1:
            langs = {
                "ğŸ‡ºğŸ‡¸ English": "en",
                "ğŸ‡¨ğŸ‡³ ç®€ä½“ä¸­æ–‡": "zh",
                "ğŸ‡ªğŸ‡¸ EspaÃ±ol": "es",
                "ğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ¸Ğ¹": "ru",
                "ğŸ‡«ğŸ‡· FranÃ§ais": "fr",
                "ğŸ‡©ğŸ‡ª Deutsch": "de",
                "ğŸ‡®ğŸ‡¹ Italiano": "it",
                "ğŸ‡¯ğŸ‡µ æ—¥æœ¬èª": "ja"
            }
            lang = st.selectbox(
                "è¯†åˆ«è¯­è¨€:", 
                options=list(langs.keys()),
                index=list(langs.values()).index(load_key("whisper.language"))
            )
            if langs[lang] != load_key("whisper.language"):
                update_key("whisper.language", langs[lang])

        with c2:
            target_language = st.text_input("ç›®æ ‡è¯­è¨€", value=load_key("target_language"))
            if target_language != load_key("target_language"):
                update_key("target_language", target_language)

        c1, c2 = st.columns(2)
        with c1:
            burn_subtitles = st.toggle("çƒ§å½•å­—å¹•", value=load_key("resolution") != "0x0")
        
        resolution_options = {
            "1080p": "1920x1080",
            "360p": "640x360"
        }
        
        with c2:
            if burn_subtitles:
                selected_resolution = st.selectbox(
                    "è§†é¢‘åˆ†è¾¨ç‡",
                    options=list(resolution_options.keys()),
                    index=list(resolution_options.values()).index(load_key("resolution")) if load_key("resolution") != "0x0" else 0
                )
                resolution = resolution_options[selected_resolution]
            else:
                resolution = "0x0"

        if resolution != load_key("resolution"):
            update_key("resolution", resolution)
        
    with st.expander("é…éŸ³è®¾ç½®", expanded=True):
        tts_methods = ["sf_fish_tts", "openai_tts", "azure_tts", "gpt_sovits", "fish_tts"]
        selected_tts_method = st.selectbox("TTSæ–¹æ³•", options=tts_methods, index=tts_methods.index(load_key("tts_method")))
        if selected_tts_method != load_key("tts_method"):
            update_key("tts_method", selected_tts_method)

        if selected_tts_method == "sf_fish_tts":
            config_input("SiliconFlow APIå¯†é’¥", "sf_fish_tts.api_key")
            
            # Add mode selection dropdown
            mode_options = {
                "preset": "preset",
                "custom": "clone(stable)",
                "dynamic": "clone(dynamic)"
            }
            selected_mode = st.selectbox(
                "æ¨¡å¼é€‰æ‹©",
                options=list(mode_options.keys()),
                format_func=lambda x: mode_options[x],
                index=list(mode_options.keys()).index(load_key("sf_fish_tts.mode")) if load_key("sf_fish_tts.mode") in mode_options.keys() else 0
            )
            if selected_mode != load_key("sf_fish_tts.mode"):
                update_key("sf_fish_tts.mode", selected_mode)
                
            if selected_mode == "preset":
                config_input("è¯­éŸ³", "sf_fish_tts.voice")

        elif selected_tts_method == "openai_tts":
            config_input("OpenAIè¯­éŸ³", "openai_tts.voice")
            config_input("OpenAI TTS APIå¯†é’¥", "openai_tts.api_key")
            config_input("OpenAI TTS APIåŸºç¡€URL", "openai_tts.base_url")

        elif selected_tts_method == "fish_tts":
            config_input("Fish TTS APIå¯†é’¥", "fish_tts.api_key")
            fish_tts_character = st.selectbox("Fish TTSè§’è‰²", options=list(load_key("fish_tts.character_id_dict").keys()), index=list(load_key("fish_tts.character_id_dict").keys()).index(load_key("fish_tts.character")))
            if fish_tts_character != load_key("fish_tts.character"):
                update_key("fish_tts.character", fish_tts_character)

        elif selected_tts_method == "azure_tts":
            config_input("Azureå¯†é’¥", "azure_tts.key")
            config_input("AzureåŒºåŸŸ", "azure_tts.region")
            config_input("Azureè¯­éŸ³", "azure_tts.voice")

        elif selected_tts_method == "gpt_sovits":
            st.info("é…ç½®GPT_SoVITSï¼Œè¯·å‚è€ƒGithubä¸»é¡µ")
            config_input("SoVITSè§’è‰²", "gpt_sovits.character")
            
            refer_mode_options = {1: "æ¨¡å¼1ï¼šä»…ç”¨æä¾›çš„å‚è€ƒéŸ³é¢‘", 2: "æ¨¡å¼2ï¼šä»…ç”¨è§†é¢‘ç¬¬1æ¡è¯­éŸ³åšå‚è€ƒ", 3: "æ¨¡å¼3ï¼šä½¿ç”¨è§†é¢‘æ¯ä¸€æ¡è¯­éŸ³åšå‚è€ƒ"}
            selected_refer_mode = st.selectbox(
                "å‚è€ƒæ¨¡å¼",
                options=list(refer_mode_options.keys()),
                format_func=lambda x: refer_mode_options[x],
                index=list(refer_mode_options.keys()).index(load_key("gpt_sovits.refer_mode")),
                help="é…ç½®GPT-SoVITSçš„å‚è€ƒéŸ³é¢‘æ¨¡å¼"
            )
            if selected_refer_mode != load_key("gpt_sovits.refer_mode"):
                update_key("gpt_sovits.refer_mode", selected_refer_mode)

def check_api(api_set):
    """æ£€æŸ¥APIé…ç½®æ˜¯å¦æœ‰æ•ˆ"""
    try:
        resp = ask_gpt(
            "This is a test, response 'message':'success' in json format.",
            response_json=True,
            log_title='None',
            check_api=True,
            api_set=api_set
        )
        return resp.get('message') == 'success'
    except Exception:
        return False
