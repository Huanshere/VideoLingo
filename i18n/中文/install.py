import os
import platform
import subprocess
import sys
import zipfile
import shutil
import time

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def install_package(*packages):
    subprocess.check_call([sys.executable, "-m", "pip", "install", *packages])

install_package("requests", "rich", "ruamel.yaml")
from core.pypi_autochoose.pypi_autochoose import main as choose_mirror

def main():
    from rich.console import Console
    from rich.table import Table
    from rich.panel import Panel

    console = Console()

    console.print(Panel.fit("å¼€å§‹å®‰è£…", style="bold magenta"))

    # æ‰§è¡Œé•œåƒé…ç½®
    console.print(Panel("é…ç½®é•œåƒ", style="bold yellow"))
    choose_mirror()

    def install_requirements():
        try:
            with open("requirements.txt", "r", encoding="utf-8") as file:
                content = file.read()
            with open("requirements.txt", "w", encoding="gbk") as file:
                file.write(content)
        except Exception as e:
            print(f"è½¬æ¢ requirements.txt æ—¶å‡ºé”™: {str(e)}")
        subprocess.check_call([sys.executable, "-m", "pip", "install", "-r", "requirements.txt"])

    def test_mirror_speed(name, base_url):
        import requests
        test_url = f"{base_url}lj1995/VoiceConversionWebUI/resolve/main/README.md"
        max_retries = 3
        timeout = 10

        for attempt in range(max_retries):
            try:
                start_time = time.time()
                response = requests.head(test_url, timeout=timeout)
                end_time = time.time()
                if response.status_code == 200:
                    speed = (end_time - start_time) * 1000 
                    return name, speed
            except requests.RequestException:
                if attempt == max_retries - 1:
                    return name, float('inf')
                time.sleep(1)  # é‡è¯•å‰ç­‰å¾…1ç§’

        return name, float('inf')

    def download_uvr_model():
        import requests
        models = {
            "HP2_all_vocals.pth": "lj1995/VoiceConversionWebUI/resolve/e992cb1bc5d777fcddce20735a899219b1d46aba/uvr5_weights/HP2_all_vocals.pth",
            "VR-DeEchoAggressive.pth": "lj1995/VoiceConversionWebUI/resolve/main/uvr5_weights/VR-DeEchoAggressive.pth"
        }
        
        mirrors = {
            "å®˜æ–¹": "https://huggingface.co/",
            "é•œåƒ": "https://hf-mirror.com/"
        }

        os.makedirs("_model_cache/uvr5_weights", exist_ok=True)

        for model_name, model_path in models.items():
            model_file_path = f"_model_cache/uvr5_weights/{model_name}"
            if not os.path.exists(model_file_path):
                print(f"æ­£åœ¨ä¸‹è½½ UVR æ¨¡å‹: {model_name}...")
                
                # æµ‹è¯•æ¯ä¸ªé•œåƒçš„é€Ÿåº¦
                speeds = []
                for mirror_name, mirror_url in mirrors.items():
                    name, speed = test_mirror_speed(mirror_name, mirror_url)
                    speeds.append((name, speed))
                    print(f"{mirror_name}é•œåƒé€Ÿåº¦: {speed:.2f} ms")

                # é€‰æ‹©æœ€å¿«çš„é•œåƒ
                fastest_mirror = min(speeds, key=lambda x: x[1])[0]
                print(f"é€‰æ‹©é•œåƒ: {fastest_mirror}")

                # ä»æœ€å¿«çš„é•œåƒä¸‹è½½
                url = mirrors[fastest_mirror] + model_path
                try:
                    response = requests.get(url, stream=True)
                    response.raise_for_status()
                    total_size = int(response.headers.get('content-length', 0))
                    
                    with open(model_file_path, "wb") as file:
                        downloaded_size = 0
                        for data in response.iter_content(chunk_size=8192):
                            size = file.write(data)
                            downloaded_size += size
                            if total_size:
                                percent = (downloaded_size / total_size) * 100
                                print(f"ä¸‹è½½è¿›åº¦: {percent:.2f}%", end="\r")
                    
                    print(f"\n{model_name} æ¨¡å‹ä¸‹è½½å®Œæˆ")
                except requests.RequestException as e:
                    print(f"ä¸‹è½½å¤±è´¥: {model_name}: {str(e)}")
            else:
                print(f"{model_name} æ¨¡å‹å·²å­˜åœ¨")

    def download_and_extract_ffmpeg():
        import requests
        system = platform.system()
        if system == "Windows":
            ffmpeg_exe = "ffmpeg.exe"
            url = "https://github.com/BtbN/FFmpeg-Builds/releases/download/latest/ffmpeg-master-latest-win64-gpl.zip"
        elif system == "Darwin":
            ffmpeg_exe = "ffmpeg"
            url = "https://evermeet.cx/ffmpeg/getrelease/zip"
        elif system == "Linux":
            ffmpeg_exe = "ffmpeg"
            url = "https://johnvansickle.com/ffmpeg/builds/ffmpeg-git-amd64-static.tar.xz"
        else:
            return

        if os.path.exists(ffmpeg_exe):
            print(f"{ffmpeg_exe} å·²å­˜åœ¨")
            return

        print("æ­£åœ¨ä¸‹è½½ FFmpeg")
        response = requests.get(url)
        if response.status_code == 200:
            filename = "ffmpeg.zip" if system in ["Windows", "Darwin"] else "ffmpeg.tar.xz"
            with open(filename, 'wb') as f:
                f.write(response.content)
            print(f"FFmpeg ä¸‹è½½å®Œæˆ: {filename}")
        
            print("æ­£åœ¨è§£å‹ FFmpeg")
            if system == "Linux":
                import tarfile
                with tarfile.open(filename) as tar_ref:
                    for member in tar_ref.getmembers():
                        if member.name.endswith("ffmpeg"):
                            member.name = os.path.basename(member.name)
                            tar_ref.extract(member)
            else:
                with zipfile.ZipFile(filename, 'r') as zip_ref:
                    for file in zip_ref.namelist():
                        if file.endswith(ffmpeg_exe):
                            zip_ref.extract(file)
                            shutil.move(os.path.join(*file.split('/')[:-1], os.path.basename(file)), os.path.basename(file))
            
            print("æ¸…ç†ä¸­")
            os.remove(filename)
            if system == "Windows":
                for item in os.listdir():
                    if os.path.isdir(item) and "ffmpeg" in item.lower():
                        shutil.rmtree(item)
            print("FFmpeg è§£å‹å®Œæˆ")
        else:
            print("ä¸‹è½½ FFmpeg å¤±è´¥")

    def install_noto_font():
        if platform.system() == 'Linux':
            try:
                # é¦–å…ˆå°è¯• apt-getï¼ˆåŸºäº Debian çš„ç³»ç»Ÿï¼‰
                subprocess.run(['sudo', 'apt-get', 'install', '-y', 'fonts-noto'], check=True)
                print("ä½¿ç”¨ apt-get æˆåŠŸå®‰è£… Noto å­—ä½“ã€‚")
            except subprocess.CalledProcessError:
                try:
                    # å¦‚æœ apt-get å¤±è´¥ï¼Œå°è¯• yumï¼ˆåŸºäº RPM çš„ç³»ç»Ÿï¼‰
                    subprocess.run(['sudo', 'yum', 'install', '-y', 'fonts-noto'], check=True)
                    print("ä½¿ç”¨ yum æˆåŠŸå®‰è£… Noto å­—ä½“ã€‚")
                except subprocess.CalledProcessError:
                    print("è‡ªåŠ¨å®‰è£… Noto å­—ä½“å¤±è´¥ã€‚è¯·æ‰‹åŠ¨å®‰è£…ã€‚")

    # ç”¨æˆ·é€‰æ‹© Whisper æ¨¡å‹
    table = Table(title="Whisper æ¨¡å‹é€‰æ‹©")
    table.add_column("é€‰é¡¹", style="cyan", no_wrap=True)
    table.add_column("æ¨¡å‹", style="magenta")
    table.add_column("æè¿°", style="green")
    table.add_row("1", "whisperX ğŸ’»", "ä½¿ç”¨ whisperX è¿›è¡Œæœ¬åœ°å¤„ç†")
    table.add_row("2", "whisperXapi â˜ï¸", "ä½¿ç”¨ whisperXapi è¿›è¡Œäº‘å¤„ç†")
    console.print(table)

    console.print("WhisperX åœ¨æ‚¨çš„æœºå™¨ä¸Šæœ¬åœ°å¤„ç†éŸ³é¢‘ï¼Œè€Œ whisperXapi ä½¿ç”¨äº‘å¤„ç†ã€‚")

    if len(sys.argv) > 1:
        choice = sys.argv[1]
    else:
        choice = console.input("è¯·è¾“å…¥æ‚¨çš„é€‰æ‹©ï¼ˆ1 æˆ– 2ï¼‰ï¼š")

    if platform.system() == 'Darwin':
        console.print(Panel("å¯¹äº MacOSï¼Œæ­£åœ¨å®‰è£… CPU ç‰ˆæœ¬çš„ PyTorch...", style="cyan"))
        subprocess.check_call([sys.executable, "-m", "pip", "install", "torch", "torchaudio"])
        if choice == '1':
            print("æ­£åœ¨å®‰è£… whisperX...")
            current_dir = os.getcwd()
            whisperx_dir = os.path.join(current_dir, "third_party", "whisperX")
            os.chdir(whisperx_dir)
            subprocess.check_call([sys.executable, "-m", "pip", "install", "-e", "."])
            os.chdir(current_dir)
    else:
        if choice == '1':
            console.print(Panel("æ­£åœ¨å®‰è£…æ”¯æŒ CUDA çš„ PyTorch...", style="cyan"))
            subprocess.check_call([sys.executable, "-m", "pip", "install", "torch==2.0.0", "torchaudio==2.0.0", "--index-url", "https://download.pytorch.org/whl/cu118"])

            print("æ­£åœ¨å®‰è£… whisperX...")
            current_dir = os.getcwd()
            whisperx_dir = os.path.join(current_dir, "third_party", "whisperX")
            os.chdir(whisperx_dir)
            subprocess.check_call([sys.executable, "-m", "pip", "install", "-e", "."])
            os.chdir(current_dir)
        elif choice == '2':
            table = Table(title="PyTorch ç‰ˆæœ¬é€‰æ‹©")
            table.add_column("é€‰é¡¹", style="cyan", no_wrap=True)
            table.add_column("æ¨¡å‹", style="magenta")
            table.add_column("æè¿°", style="green")
            table.add_row("1", "CPU", "å¦‚æœæ‚¨ä½¿ç”¨ Macã€é NVIDIA GPU æˆ–ä¸éœ€è¦ GPU åŠ é€Ÿï¼Œè¯·é€‰æ‹©æ­¤é¡¹")
            table.add_row("2", "GPU", "æ˜¾è‘—åŠ å¿« UVR5 è¯­éŸ³åˆ†ç¦»é€Ÿåº¦ã€‚å¦‚æœæ‚¨éœ€è¦é…éŸ³åŠŸèƒ½å¹¶æ‹¥æœ‰ NVIDIA GPUï¼Œå¼ºçƒˆæ¨èã€‚")
            console.print(table)

            torch_choice = console.input("è¯·è¾“å…¥é€‰é¡¹ç¼–å·ï¼ˆ1 è¡¨ç¤º CPUï¼Œ2 è¡¨ç¤º GPUï¼‰ï¼š")
            if torch_choice == '1':
                console.print(Panel("æ­£åœ¨å®‰è£… CPU ç‰ˆæœ¬çš„ PyTorch...", style="cyan"))
                subprocess.check_call([sys.executable, "-m", "pip", "install", "torch", "torchaudio"])
            elif torch_choice == '2':
                console.print(Panel("æ­£åœ¨å®‰è£…æ”¯æŒ CUDA 11.8 çš„ GPU ç‰ˆæœ¬ PyTorch...", style="cyan"))
                subprocess.check_call([sys.executable, "-m", "pip", "install", "torch", "torchaudio", "--index-url", "https://download.pytorch.org/whl/cu118"])
            else:
                console.print("æ— æ•ˆé€‰æ‹©ã€‚é»˜è®¤ä½¿ç”¨ CPU ç‰ˆæœ¬ã€‚")
                subprocess.check_call([sys.executable, "-m", "pip", "install", "torch", "torchaudio"])
        else:
            raise ValueError("æ— æ•ˆé€‰æ‹©ã€‚è¯·è¾“å…¥ 1 æˆ– 2ã€‚è¯·é‡è¯•ã€‚")

    install_noto_font()
    install_requirements()
    download_uvr_model()  
    download_and_extract_ffmpeg()
    
    console.print(Panel.fit("å®‰è£…å®Œæˆ", style="bold green"))
    console.print("è¦å¯åŠ¨åº”ç”¨ç¨‹åºï¼Œè¯·è¿è¡Œï¼š")
    console.print("[bold cyan]streamlit run st.py[/bold cyan]")

if __name__ == "__main__":
    main()
