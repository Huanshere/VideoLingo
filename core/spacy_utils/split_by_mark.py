import warnings
warnings.filterwarnings("ignore", category=FutureWarning)
import os,sys
import pandas as pd
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
from core.spacy_utils.load_nlp_model import init_nlp
from core.step2_whisper import get_whisper_language
from config import get_joiner, WHISPER_LANGUAGE

def split_by_mark(nlp):
    language = get_whisper_language() if WHISPER_LANGUAGE == 'auto' else WHISPER_LANGUAGE # è€ƒè™‘å¼ºåˆ¶è‹±æ–‡çš„æƒ…å†µ
    joiner = get_joiner(language)
    print(f"ğŸ” æ­£åœ¨ä½¿ç”¨ {language} è¯­è¨€çš„æ‹¼æ¥æ–¹å¼: '{joiner}'")
    chunks = pd.read_excel("output/log/cleaned_chunks.xlsx")
    chunks.text = chunks.text.apply(lambda x: x.strip('"'))
    
    # ç”¨ joiner æ‹¼æ¥
    input_text = joiner.join(chunks.text.to_list())

    doc = nlp(input_text)
    assert doc.has_annotation("SENT_START")

    sentences_by_mark = [sent.text for sent in doc.sents]

    with open("output/log/sentence_by_mark.txt", "w", encoding="utf-8") as output_file:
        for sentence in sentences_by_mark:
            output_file.write(sentence + "\n")

    print("ğŸ’¾ Sentences split by punctuation marks saved to â†’  `sentences_by_mark.txt`")

if __name__ == "__main__":
    # nlp = init_nlp()
    # split_by_mark(nlp)

    s = """ãã†ã§ã€‚"""
    nlp = init_nlp()
    doc = nlp(s)
    print(doc)
    assert doc.has_annotation("SENT_START")

    sentences_by_mark = [sent.text for sent in doc.sents]
    print(sentences_by_mark)

