import sys, os
import pandas as pd
from typing import List, Tuple
import concurrent.futures
import json
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.step3_2_splitbymeaning import split_sentence
from core.ask_gpt import ask_gpt, step5_align_model
from core.prompts_storage import get_align_prompt
from config import TARGET_LANGUAGE, MAX_ENGLISH_LENGTH, MAX_TARGET_LANGUAGE_LENGTH

# TODO you can modify your own function here
def calc_len(text: str) -> float:
    # ğŸ‡¨ğŸ‡³ characters are counted as 1, others are counted as 0.75
    if not isinstance(text, str):
        print(f"ğŸš¨ Warning: calc_len received a non-string input: {text}")
        text = str(text)
    if 'ä¸­æ–‡' in TARGET_LANGUAGE or 'cn' in TARGET_LANGUAGE: 
        return sum(1 if ord(char) > 127 else 0.75 for char in text)
    else:
        return len(text)

def align_subs(en_sub: str, tr_sub: str, en_part: str) -> Tuple[List[str], List[str]]:
    align_prompt = get_align_prompt(en_sub, tr_sub, en_part, target_language=TARGET_LANGUAGE)
    
    parsed = ask_gpt(align_prompt, model=step5_align_model, response_json=True, log_title='align_subs')

    best = int(parsed['best_way'])
    align_data = parsed[f'align_way_{best}']
    
    en_parts = en_part.split('\n')
    tr_parts = [item[f'target_part_{i+1}'].strip() for i, item in enumerate(align_data)]
    
    print(f"ğŸ”— Aligned parts:\nSRC_LANG:    {en_parts}\nTARGET_LANG: {tr_parts}\n================")
    return en_parts, tr_parts

def split_align_subs(en_lines: List[str], tr_lines: List[str], max_en_len=80, max_tr_len=30, max_retry=5) -> Tuple[List[str], List[str]]:
    for attempt in range(max_retry):
        print(f"ğŸ”„ Splitting attempt {attempt + 1}")
        to_split = []
        
        for i, (en, tr) in enumerate(zip(en_lines, tr_lines)):
            if len(en) > max_en_len or calc_len(tr) > max_tr_len:
                to_split.append(i)
                print(f"ğŸ“ Line {i} needs splitting:\nSRC_LANG:    {en}\nTARGET_LANG: {tr}\n================")
        
        def process(i):
            split_en = split_sentence(en_lines[i], num_parts=2).strip()
            en_lines[i], tr_lines[i] = align_subs(en_lines[i], tr_lines[i], split_en)
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:
            executor.map(process, to_split)
        
        # Flatten `en_lines` and `tr_lines`
        en_lines = [item for sublist in en_lines for item in (sublist if isinstance(sublist, list) else [sublist])]
        tr_lines = [item for sublist in tr_lines for item in (sublist if isinstance(sublist, list) else [sublist])]
        
        if all(len(en) <= max_en_len for en in en_lines) and all(calc_len(tr) <= max_tr_len for tr in tr_lines):
            break
    
    return en_lines, tr_lines

import os

def check_subtitle_files():
    en_subtitle_file = "output/english_subtitles.srt"
    tr_subtitle_file = "output/translated_subtitles.srt"
    
    if not os.path.exists(en_subtitle_file):
        print(f"ğŸš¨ è‹±æ–‡å­—å¹•æ–‡ä»¶ '{en_subtitle_file}' ä¸å­˜åœ¨ã€‚")
        return False
    
    if not os.path.exists(tr_subtitle_file):
        print(f"ğŸš¨ ç¿»è¯‘å­—å¹•æ–‡ä»¶ '{tr_subtitle_file}' ä¸å­˜åœ¨ã€‚")
        return False
    
    print("âœ… å­—å¹•æ–‡ä»¶æ£€æŸ¥é€šè¿‡ã€‚")
    return True

def split_for_sub_main():
    input_file = "output/log/translation_results.xlsx"
    output_file = "output/log/translation_results_for_subtitles.xlsx"
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_file):
        print(f"ğŸš¨ è¾“å…¥æ–‡ä»¶ '{input_file}' ä¸å­˜åœ¨ã€‚è¯·æ£€æŸ¥ä¹‹å‰çš„ç¿»è¯‘æ­¥éª¤ã€‚")
        return False

    # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
    if os.path.exists(output_file):
        print(f"ğŸš¨ è¾“å‡ºæ–‡ä»¶ '{output_file}' å·²å­˜åœ¨ï¼Œè·³è¿‡æ­¤æ­¥éª¤ã€‚")
        return True

    print('ğŸš€ å¼€å§‹å­—å¹•åˆ†å‰²å¤„ç†...')
    
    try:
        df = pd.read_excel(input_file)
    except Exception as e:
        print(f"ğŸš¨ è¯»å–è¾“å…¥æ–‡ä»¶ '{input_file}' æ—¶å‡ºé”™ï¼š{str(e)}")
        return False

    en_lines = df['English'].tolist()
    tr_lines = df['Translation'].tolist()

    if not en_lines or not tr_lines:
        print("ğŸš¨ è‹±æ–‡æˆ–ç¿»è¯‘å­—å¹•ä¸ºç©ºã€‚è¯·æ£€æŸ¥è¾“å…¥æ–‡ä»¶ã€‚")
        return False

    en_lines, tr_lines = split_align_subs(en_lines, tr_lines, MAX_ENGLISH_LENGTH, MAX_TARGET_LANGUAGE_LENGTH)
    
    # ä¿å­˜åˆ†å‰²åçš„å­—å¹•
    split_subtitles = {'English': en_lines, 'Translation': tr_lines}
    pd.DataFrame(split_subtitles).to_excel(output_file, index=False)
    
    json_output_file = 'output/split_subtitles.json'
    os.makedirs(os.path.dirname(json_output_file), exist_ok=True)
    with open(json_output_file, 'w', encoding='utf-8') as f:
        json.dump(split_subtitles, f, ensure_ascii=False, indent=4)

    # åœ¨å‡½æ•°æœ«å°¾æ·»åŠ æ–‡ä»¶æ£€æŸ¥
    if not check_subtitle_files():
        print("ğŸš¨ å­—å¹•æ–‡ä»¶æœªæ­£ç¡®ç”Ÿæˆã€‚è¯·æ£€æŸ¥ä¹‹å‰çš„æ­¥éª¤ã€‚")
        return False
    
    print(f"âœ… å­—å¹•åˆ†å‰²å¤„ç†å®Œæˆï¼")
    print(f"åˆ†å‰²åçš„å­—å¹•å·²ä¿å­˜åˆ° {output_file} å’Œ {json_output_file}")
    return True

if __name__ == '__main__':
    split_for_sub_main()
