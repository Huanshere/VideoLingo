import re
import subprocess
from pydub import AudioSegment
import os,sys, json
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from uvr5.uvr5_for_submagic import uvr5_for_submagic

def parse_srt(srt_content):
    pattern = re.compile(r'(\d+)\n(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})\n((?:.+\n)+)')
    matches = pattern.findall(srt_content)
    return [{'index': int(m[0]), 'start': m[1], 'end': m[2], 'text': m[3].strip()} for m in matches]  # è§£æSRTå†…å®¹

def time_to_ms(time_str):
    h, m, s = time_str.split(':')
    s, ms = s.split(',')
    return int(h) * 3600000 + int(m) * 60000 + int(s) * 1000 + int(ms)  # å°†æ—¶é—´å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ¯«ç§’

def extract_audio(input_video, start_time, end_time, output_file):
    start_ms = time_to_ms(start_time)
    end_ms = time_to_ms(end_time)
    
    # å°†è§†é¢‘è½¬æ¢ä¸ºéŸ³é¢‘
    temp_audio = 'temp_audio.wav'
    subprocess.run([
        'ffmpeg', '-i', input_video, '-vn', '-acodec', 'pcm_s16le', '-ar', '44100', '-ac', '2', temp_audio
    ], check=True)
    
    # æå–ç‰¹å®šéƒ¨åˆ†éŸ³é¢‘
    audio = AudioSegment.from_wav(temp_audio)
    extract = audio[start_ms:end_ms]
    extract.export(output_file, format="wav")
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    os.remove(temp_audio)

def step8_main(input_video, DUBBING_CHARACTER = "Huanyu"):
    # å¦‚æœ'output/audio/background.wav'å­˜åœ¨ï¼Œåˆ™returnè·³è¿‡
    if os.path.exists('output/audio/background.wav'):
        print('output/audio/background.wav already exists, skip.')
        return
    # è¯»å–SRTæ–‡ä»¶å†…å®¹
    with open('output/audio/english_subtitles_for_audio.srt', 'r', encoding='utf-8') as f:
        srt_content = f.read()  
    subtitles = parse_srt(srt_content)
    
    # step1: é€‰æ‹©å¹¶æå–ç¬¬ä¸€ä¸ªå¤§äº5ç§’çš„å­—å¹• è·³è¿‡å‰ä¸¤ä¸ªï¼ˆå¾ˆå¤šæ—¶å€™ç¬¬ä¸€ä¸ªä¼šæœ‰é—®é¢˜ï¼‰
    target_subtitle = None
    skipped = 0
    for subtitle in subtitles:
        if skipped < 2:
            skipped += 1
            continue
        duration = time_to_ms(subtitle['end']) - time_to_ms(subtitle['start'])
        if duration > 5000:
            target_subtitle = subtitle
            break
    
    if not target_subtitle:
        target_subtitle = subtitles[2] if len(subtitles) > 2 else subtitles[0]
        
    if target_subtitle:
        print(f"Selected subtitle: {target_subtitle['text']}")  # é€‰æ‹©çš„å­—å¹•
        print(f"Start time: {target_subtitle['start']}")  # å¼€å§‹æ—¶é—´
        print(f"End time: {target_subtitle['end']}")  # ç»“æŸæ—¶é—´
        
        # ä½¿ç”¨å­—å¹•å†…å®¹å‘½åéŸ³é¢‘æ–‡ä»¶ï¼Œå¹¶ç§»é™¤éæ³•å­—ç¬¦
        cleaned_text = re.sub(r'[\\/*?:"<>|]', '', target_subtitle['text'])
        audio_filename = f"output/audio/{cleaned_text}.wav"
        extract_audio(input_video, target_subtitle['start'], target_subtitle['end'], audio_filename)
        print('Starting uvr5_for_submagic...')  # å¼€å§‹å¤„ç†éŸ³é¢‘
        uvr5_for_submagic(audio_filename, 'output/audio')
        os.remove(f"output/audio/instrument_{os.path.basename(audio_filename)}_10.wav")  # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ ğŸ§¹
        os.remove(audio_filename)  # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ ğŸ§¹
        os.rename(f"output/audio/vocal_{os.path.basename(audio_filename)}_10.wav", audio_filename)  # é‡å‘½åæ–‡ä»¶ ğŸ“›
        # remove any wav or mp3 under # move to GPT-SoVITS-Inference/trained/{DUBBING_CHARACTER}
        for file in os.listdir(f"GPT-SoVITS-Inference/trained/{DUBBING_CHARACTER}"):
            if file.endswith(".wav") or file.endswith(".mp3"):
                os.remove(f"GPT-SoVITS-Inference/trained/{DUBBING_CHARACTER}/{file}")

        # === æ¥ä¸‹æ¥æ˜¯å°†éŸ³é¢‘æ–‡ä»¶ç§»åŠ¨åˆ°GPT-SoVITS-Inference/trained/{DUBBING_CHARACTER} ===
        # move to GPT-SoVITS-Inference/trained/{DUBBING_CHARACTER}
        os.rename(audio_filename, f"GPT-SoVITS-Inference/trained/{DUBBING_CHARACTER}/{os.path.basename(audio_filename)}")  # é‡å‘½åæ–‡ä»¶ ğŸ“›
        
        # å®ŒæˆTODOéƒ¨åˆ†
        with open(f"GPT-SoVITS-Inference/trained/{DUBBING_CHARACTER}/infer_config.json", 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        config["emotion_list"]["default"]["ref_wav_path"] = os.path.basename(audio_filename)
        config["emotion_list"]["default"]["prompt_text"] = os.path.basename(audio_filename).replace(".wav", "")
        
        with open(f"GPT-SoVITS-Inference/trained/{DUBBING_CHARACTER}/infer_config.json", 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=4)

        print(f"Audio extracted and cleaned and saved as {audio_filename}")  # éŸ³é¢‘å¤„ç†å®Œæˆ
    else:
        print("No subtitles found.")  # æœªæ‰¾åˆ°å­—å¹•

    # step2: æå–æ•´ä¸ªè§†é¢‘çš„éŸ³é¢‘
    full_audio_path = 'output/audio/full_audio.wav'
    print("Extracting full audio...")  # æå–å®Œæ•´éŸ³é¢‘
    subprocess.run([
        'ffmpeg', '-i', input_video, '-vn', '-acodec', 'pcm_s16le', '-ar', '44100', '-ac', '2', full_audio_path
    ], check=True)
    print('Starting uvr5_for_submagic for full audio...')  # å¼€å§‹å¤„ç†å®Œæ•´éŸ³é¢‘
    uvr5_for_submagic(full_audio_path, 'output/audio')
    os.remove(full_audio_path)  # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ ğŸ§¹
    os.rename('output/audio/vocal_full_audio.wav_10.wav', 'output/audio/original_vocal.wav')  # é‡å‘½åæ–‡ä»¶ ğŸ“›
    os.rename('output/audio/instrument_full_audio.wav_10.wav', 'output/audio/background.wav')  # é‡å‘½åæ–‡ä»¶ ğŸ“›
    print("Full audio extracted and cleaned and saved as original_vocal.wav and background.wav")  # å®Œæ•´éŸ³é¢‘å¤„ç†å®Œæˆ

if __name__ == "__main__":
    import glob  
    input_video = (glob.glob("*.mp4") + glob.glob("*.webm"))[0]
    step8_main(input_video)