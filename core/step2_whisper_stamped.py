import os,sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import subprocess
import whisper_timestamped as whisper
import torch
import pandas as pd
from typing import List, Dict
import warnings
warnings.filterwarnings("ignore")
from config import WHISPER_MODEL, MODEL_DIR

def convert_video_to_audio_and_transcribe(input_file: str):
    # ğŸ¬â¡ï¸ğŸµâ¡ï¸ğŸ“Š Convert video to audio and transcribe
    audio_file = os.path.splitext(input_file)[0] + '_temp.mp3'
    
    try:
        if not os.path.exists(audio_file):
            # Convert video to audio
            ffmpeg_cmd = [
                'ffmpeg',
                '-i', input_file,
                '-vn',
                '-acodec', 'libmp3lame',
                '-ar', '16000',
                '-b:a', '64k',
                audio_file
            ]
            print(f"ğŸ¬â¡ï¸ğŸµ æ­£åœ¨è½¬æ¢ä¸ºéŸ³é¢‘......")
            subprocess.run(ffmpeg_cmd, check=True, stderr=subprocess.PIPE)
            print(f"ğŸ¬â¡ï¸ğŸµ å·²å°† <{input_file}> è½¬æ¢ä¸º <{audio_file}>\n")
        
        # Check file size
        if os.path.getsize(audio_file) > 25 * 1024 * 1024:
            print("âš ï¸ æ–‡ä»¶å¤§å°è¶…è¿‡25MBã€‚è¯·ä½¿ç”¨æ›´å°çš„æ–‡ä»¶ã€‚")
            return None
        
        # Transcribe audio
        device = 'cuda:0' if torch.cuda.is_available() else 'cpu' # sadly whisper does not support mps on mac
        print(f"ğŸš€ æ­£åœ¨å¯åŠ¨Whisper...\nğŸ–¥ï¸  ASRè®¾å¤‡: {device}")
        
        audio = whisper.load_audio(audio_file)
        os.makedirs(MODEL_DIR, exist_ok=True)
        model = whisper.load_model(WHISPER_MODEL, device=device, download_root=MODEL_DIR)
        result = whisper.transcribe(model, audio, language="en")
        
        # Process transcription results
        all_words: List[Dict[str, float]] = [
            {'text': f"{word['text']}", 'start': word['start'], 'end': word['end']}
            for segment in result['segments']
            for word in segment['words']
        ]
        
        df = pd.DataFrame(all_words)
        return df
    
    except subprocess.CalledProcessError as e:
        print(f"âŒ è½¬æ¢ {input_file} æ—¶å‡ºé”™: {e.stderr.decode()}")
        return None
    finally:
        if os.path.exists(audio_file):
            os.remove(audio_file)
            print(f"ğŸ—‘ï¸ ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶ {audio_file} å·²è¢«åˆ é™¤ã€‚")


def save_results(df: pd.DataFrame):
    # ğŸ’¾ Save transcription results as Excel and text files
    os.makedirs('output', exist_ok=True)
    os.makedirs('output/log', exist_ok=True)
    excel_path = os.path.join('output/log', "cleaned_chunks.xlsx")
    # ç»™df[text]åˆ—éƒ½åŠ ä¸Š""ï¼Œé˜²æ­¢æ•°å­—è¢«excelè‡ªåŠ¨è½¬æ¢ä¸ºæ•°å­—
    df['text'] = df['text'].apply(lambda x: f'"{x}"')
    df.to_excel(excel_path, index=False)
    print(f"ğŸ“Š Excelæ–‡ä»¶å·²ä¿å­˜åˆ° {excel_path}")

def transcript(video_file: StopIteration):
    if not os.path.exists("output/log/cleaned_chunks.xlsx"):
        # ğŸ¥â¡ï¸ğŸ“ Transcribe video to text
        df = convert_video_to_audio_and_transcribe(video_file)
        if df is not None:
            save_results(df)
    else:
        print("ğŸ“Š è½¬å½•ç»“æœå·²å­˜åœ¨ï¼Œè·³è¿‡è½¬å½•æ­¥éª¤ã€‚")

if __name__ == "__main__":
    transcript("KUNG FU PANDA 4 ï½œ Official Trailer.mp4")